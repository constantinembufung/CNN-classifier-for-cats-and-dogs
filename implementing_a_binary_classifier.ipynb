{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "implementing a binary classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8ASmqvEyAc+OK5Wa8vpOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/constantinembufung/CNN-classifier-for-cats-and-dogs/blob/master/implementing_a_binary_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bJxhkzwvY1z"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EIXdDv9vEVG",
        "outputId": "773fc758-9023-43be-a796-9ec94f3b3848"
      },
      "source": [
        "X = tf.Variable([[0.,0.],[0.,1.],[1.,0.],[1.,1.]], tf.float32)\n",
        "Y = tf.Variable([0,1,1,1], dtype = tf.float32)\n",
        "print(X)\n",
        "Y = tf.reshape(Y, [4,1])\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(4, 2) dtype=float32, numpy=\n",
            "array([[0., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 1.]], dtype=float32)>\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLNsJuf9vgCJ",
        "outputId": "8925bf64-c843-4ce3-e442-70703cf03964"
      },
      "source": [
        "NUM_FEATURES = X.shape[1]\n",
        "OUTPUT_SIZE = 1\n",
        "W = tf.Variable(tf.zeros([NUM_FEATURES, OUTPUT_SIZE ]),tf.float32)\n",
        "print(W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.],\n",
            "       [0.]], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbjBR1cFv6zN",
        "outputId": "32ccaf85-0bb8-4e87-8f5c-08c23b86a1d9"
      },
      "source": [
        "B = tf.Variable(tf.zeros([OUTPUT_SIZE, 1]), tf.float32)\n",
        "print(B)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[0.]], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vRnYy1xwkpo",
        "outputId": "f9144e61-b40e-4b92-9dc5-7f31e864e7cc"
      },
      "source": [
        "output = tf.sigmoid(z)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
              "array([[0.5],\n",
              "       [0.5],\n",
              "       [0.5],\n",
              "       [0.5]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3SNo9x7xuwj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGzX9sMJxwQ0"
      },
      "source": [
        "PERCEPTION IN TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g0tph8Lxzci",
        "outputId": "4fa8ad99-c072-4f07-fc62-54c89e0a641b"
      },
      "source": [
        "def perception(X):\n",
        "  z = tf.add(tf.matmul(X,W),B)\n",
        "  output = tf.sigmoid(z)\n",
        "  return output\n",
        "\n",
        "print(perception(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfrFMWtV2_8H"
      },
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "no_of_epochs = 1000\n",
        "for n in range(no_of_epochs):\n",
        "  loss = lambda:abs(tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,\n",
        "                                                             logits=perception(X))))\n",
        "  optimizer.minimize(loss,[W,B])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tECBQla6EUt"
      },
      "source": [
        "** Implementing a Binary Classifier**"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHiPjtYm6PIT"
      },
      "source": [
        "** Implementing a Binary Classifier**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4kxo0556QYr"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ShOYvp2R6iTK",
        "outputId": "223e4186-1b97-4ddb-8165-97a699572d93"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.6487</td>\n",
              "      <td>4.5192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.5438</td>\n",
              "      <td>2.4443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.8990</td>\n",
              "      <td>4.2409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2.4711</td>\n",
              "      <td>5.8097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3.3590</td>\n",
              "      <td>6.4423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label      x1      x2\n",
              "0      1  2.6487  4.5192\n",
              "1      1  1.5438  2.4443\n",
              "2      1  1.8990  4.2409\n",
              "3      1  2.4711  5.8097\n",
              "4      1  3.3590  6.4423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "gDKYkxEU6usX",
        "outputId": "fce9bd7f-1c51-4719-d0aa-87ce220def5c"
      },
      "source": [
        "plt.scatter(df[df['label'] == 0]['x1'], df[df['label']== 0]['x2'], marker='*')\n",
        "plt.scatter(df[df['label'] == 1]['x1'], df[df['label'] == 1]['x2'], marker='<')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6a526a8198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5aO1zdQ7fz6"
      },
      "source": [
        "X_input = df[['x1','x2']].values\n",
        "y_label = df[['label']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m4SRAHb7qDj"
      },
      "source": [
        "x = tf.Variable(X_input, dtype=tf.float32)\n",
        "y = tf.Variable(y_label, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGGkMw4B9aBZ"
      },
      "source": [
        "Number_of_features = 2\n",
        "Number_of_units = 1\n",
        "learning_rate = 0.01\n",
        "\n",
        "# weights and bias\n",
        "weight = tf.Variable(tf.zeros([Number_of_features, Number_of_units]))  \n",
        "bias = tf.Variable(tf.zeros([Number_of_units]))\n",
        "\n",
        "#optimizer\n",
        "optimizer = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Clbsp_72_c"
      },
      "source": [
        "def perceptron(x):\n",
        "    z = tf.add(tf.matmul(x,weight),bias)\n",
        "    output = tf.sigmoid(z)\n",
        "    return output\n",
        "\n",
        "def train(i):\n",
        "    for n in range(i):\n",
        "        loss = lambda: abs(tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=perceptron(x))))\n",
        "        optimizer.minimize(loss, [weight, bias])\n",
        " \n",
        "#Train the perceptron\n",
        "train(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk6IpvQh9MIP",
        "outputId": "97ef0757-f95c-4a6f-a904-7b4dfdea0632"
      },
      "source": [
        "tf.print(weight, bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.844034076]\n",
            " [0.673354685]] [0.059394788]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j1rzpvu9ktc"
      },
      "source": [
        "ypred = perceptron(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJulZlnz9mzs"
      },
      "source": [
        "ypred = tf.round(ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RbDd8jj9oxl",
        "outputId": "ddc53c76-ac61-4760-bc33-a64dbc3243c2"
      },
      "source": [
        "\n",
        "acc = accuracy_score(y.numpy(), ypred.numpy())\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC73XTBN9q4J",
        "outputId": "d2af23e4-fabb-40e6-bc5b-4ffdff656492"
      },
      "source": [
        "cnf_matrix = confusion_matrix(y.numpy(), ypred.numpy())\n",
        "print(cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[12  0]\n",
            " [ 0  9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o_TrVzT-5Cy"
      },
      "source": [
        "**Implementing Multiclass Classification using a perception**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mitAJp_V-4gd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pandas import get_dummies\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "s9a888nMAMZS",
        "outputId": "71e9894f-de5c-4fcf-83d2-5aaf0a244b41"
      },
      "source": [
        "df = pd.read_csv('iris.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>petallength</th>\n",
              "      <th>petalwidth</th>\n",
              "      <th>sepallength</th>\n",
              "      <th>sepalwidth</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   petallength  petalwidth  sepallength  sepalwidth  species\n",
              "0          5.1         3.5          1.4         0.2        0\n",
              "1          4.9         3.0          1.4         0.2        0\n",
              "2          4.7         3.2          1.3         0.2        0\n",
              "3          4.6         3.1          1.5         0.2        0\n",
              "4          5.0         3.6          1.4         0.2        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xPrAV4V3AcA9",
        "outputId": "f52a9c00-256c-4b41-fc66-bf231d7adddb"
      },
      "source": [
        "plt.scatter(df[df['species'] == 0]['sepallength'], df[df['species'] == 0]['sepalwidth'], marker='*')\n",
        "plt.scatter(df[df['species'] == 1]['sepallength'], df[df['species'] == 1]['sepalwidth'], marker='<')\n",
        "plt.scatter(df[df['species'] == 2]['sepallength'], df[df['species'] == 2]['sepalwidth'], marker='o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6a524e4358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mfksZVaBIAs",
        "outputId": "6f5be836-49eb-4f0a-91e4-8e5c45ce93ed"
      },
      "source": [
        "x = df[['petallength','petalwidth','sepallength','sepalwidth']].values\n",
        "y = df['species'].values\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KINs-E_aBaLY",
        "outputId": "125ac324-c8ef-4541-b514-a5f5e81b931a"
      },
      "source": [
        "y = get_dummies(y)\n",
        "y = y.values\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kAmlbjJBsr5"
      },
      "source": [
        "x = tf.Variable(x, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwU6UdwsBzPg"
      },
      "source": [
        "Number_of_features = 4\n",
        "Number_of_units = 3 \n",
        " \n",
        "# weights and bias\n",
        "weight = tf.Variable(tf.zeros([Number_of_features, Number_of_units]))  \n",
        "bias = tf.Variable(tf.zeros([Number_of_units]))\n",
        " \n",
        "def perceptron(x):\n",
        "    z = tf.add(tf.matmul(x, weight), bias)\n",
        "    output = tf.nn.softmax(z)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-oZtJvCJg9"
      },
      "source": [
        "optimizer = tf.optimizers.Adam(.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxnCe4q-CTYp"
      },
      "source": [
        "def train(i):\n",
        "    for n in range(i):\n",
        "        loss=lambda: abs(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "  labels=y, logits=perceptron(x))))\n",
        "        optimizer.minimize(loss, [weight, bias])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF20aeZQCWll",
        "outputId": "28d4cba1-942b-461b-a5be-835a6e0ed90b"
      },
      "source": [
        "train(1000)\n",
        "tf.print(weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.68431 0.895632744 -1.01323462]\n",
            " [2.6424644 -1.13437772 -3.20665407]\n",
            " [-2.96634197 -0.129377574 3.25728416]\n",
            " [-2.97383833 -3.13501668 3.23136568]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCzR46hcCftX",
        "outputId": "30fb7015-2c43-4dff-c3f6-0c3508e04b77"
      },
      "source": [
        "ypred=perceptron(x)\n",
        "ypred=tf.round(ypred)\n",
        "accuracy_score(y, ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv2j_bIjDEWx"
      },
      "source": [
        "MNIST multiclassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6lMlNhFDHdx"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pandas import get_dummies\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i457G89DRFT"
      },
      "source": [
        "\n",
        "mnist = tf.keras.datasets.mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGy1i0AsDL-8",
        "outputId": "b7351d89-40e9-4789-d018-edd13fc49876"
      },
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BolHtl1wDZ9Z"
      },
      "source": [
        "train_features, test_features = train_features / 255.0, test_features / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkihn0_DicM"
      },
      "source": [
        "x = tf.reshape(train_features,[60000, 784])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ehxAemMDkqr"
      },
      "source": [
        "x = tf.Variable(x)\n",
        "x = tf.cast(x, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGSpQagsDmsZ"
      },
      "source": [
        "y_hot = get_dummies(train_labels)\n",
        "y = y_hot.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW-3uPEJDq2I"
      },
      "source": [
        "#defining the parameters\n",
        "Number_of_features = 784\n",
        "Number_of_units = 10  \n",
        "# weights and bias\n",
        "weight = tf.Variable(tf.zeros([Number_of_features, Number_of_units]))\n",
        "bias = tf.Variable(tf.zeros([Number_of_units]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnaUdAyoD8Qi"
      },
      "source": [
        "#perceptron definition\n",
        "def perceptron(x):\n",
        "    z = tf.add(tf.matmul(x,weight),bias)\n",
        "    output = tf.nn.softmax(z)\n",
        "    return output\n",
        " \n",
        " #optimizer\n",
        "optimizer = tf.optimizers.Adam(.01)\n",
        " \n",
        "#training definition\n",
        "def train(i):\n",
        "    for n in range(i):\n",
        "        loss=lambda: abs(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=perceptron(x))))\n",
        "        optimizer.minimize(loss, [weight, bias])\n",
        " \n",
        "#Train the network\n",
        "train(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78x9FiubFAJq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYmhZ2ePDusm"
      },
      "source": [
        "# Prepare the test data to measure the accuracy. \n",
        "test = tf.reshape(test_features, [10000, 784])\n",
        "test = tf.Variable(test)\n",
        "test = tf.cast(test, tf.float32)\n",
        "test_hot = get_dummies(test_labels)\n",
        "test_matrix = test_hot.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPv8pYDRDyyY"
      },
      "source": [
        "ypred = perceptron(test)\n",
        "ypred = tf.round(ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3pCGOtGD1SE",
        "outputId": "979511f6-0d78-467e-b2d1-e44e2c5dbe86"
      },
      "source": [
        "accuracy_score(test_hot, ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eYuF5KPFBW7"
      },
      "source": [
        "**Binary Classification Using Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "F2EtcPdvFE28",
        "outputId": "a54b6761-0631-411a-91c1-f73e15e5fe54"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Import Keras libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.6487</td>\n",
              "      <td>4.5192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.5438</td>\n",
              "      <td>2.4443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.8990</td>\n",
              "      <td>4.2409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2.4711</td>\n",
              "      <td>5.8097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3.3590</td>\n",
              "      <td>6.4423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label      x1      x2\n",
              "0      1  2.6487  4.5192\n",
              "1      1  1.5438  2.4443\n",
              "2      1  1.8990  4.2409\n",
              "3      1  2.4711  5.8097\n",
              "4      1  3.3590  6.4423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HsxTd7UDFMVw",
        "outputId": "bcde76a8-d418-4bdc-d16d-0c6db9518920"
      },
      "source": [
        "plt.scatter(df[df['label'] == 0]['x1'], df[df['label'] == 0]['x2'], marker='*')\n",
        "plt.scatter(df[df['label'] == 1]['x1'], df[df['label'] == 1]['x2'], marker='<')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6a524aef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ohs42MFQNW"
      },
      "source": [
        "x_input = df[['x1','x2']].values\n",
        "y_label = df[['label']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtVMyUd0FUVg"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=1, input_dim=2, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu5TgjELFY_3",
        "outputId": "57bbd940-2f1c-4232-b3ff-8a9596df3a63"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz0ssBG5FiJH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAOYf5aPFeXG",
        "outputId": "fdd9592c-a4ed-4312-db94-2353af4119b9"
      },
      "source": [
        "model.fit(x_input, y_label, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6200 - accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.6176 - accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6153 - accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6129 - accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6106 - accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.6082 - accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6059 - accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6035 - accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6012 - accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5988 - accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5965 - accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5942 - accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5918 - accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5895 - accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5871 - accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5848 - accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5825 - accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5801 - accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5778 - accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5755 - accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5731 - accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5708 - accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5685 - accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5662 - accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5638 - accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5615 - accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5592 - accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5569 - accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5545 - accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5522 - accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5499 - accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5476 - accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5453 - accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5430 - accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5407 - accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5384 - accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5361 - accuracy: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5338 - accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5315 - accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5292 - accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5269 - accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5246 - accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5223 - accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5200 - accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5177 - accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5154 - accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5131 - accuracy: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5109 - accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5086 - accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5063 - accuracy: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5040 - accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5018 - accuracy: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4995 - accuracy: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4972 - accuracy: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4949 - accuracy: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4927 - accuracy: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4904 - accuracy: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4882 - accuracy: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4859 - accuracy: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4836 - accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4814 - accuracy: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4791 - accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4769 - accuracy: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4746 - accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4724 - accuracy: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4701 - accuracy: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4679 - accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4656 - accuracy: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4634 - accuracy: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4612 - accuracy: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4589 - accuracy: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4567 - accuracy: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4545 - accuracy: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4522 - accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4500 - accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4478 - accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4456 - accuracy: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4433 - accuracy: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4411 - accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4389 - accuracy: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4367 - accuracy: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4345 - accuracy: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4323 - accuracy: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4301 - accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4279 - accuracy: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4257 - accuracy: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4235 - accuracy: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4213 - accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4147 - accuracy: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4125 - accuracy: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4103 - accuracy: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4081 - accuracy: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4059 - accuracy: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4037 - accuracy: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4016 - accuracy: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3994 - accuracy: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3972 - accuracy: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3950 - accuracy: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3929 - accuracy: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3907 - accuracy: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3885 - accuracy: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3864 - accuracy: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3842 - accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3820 - accuracy: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3799 - accuracy: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3777 - accuracy: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3756 - accuracy: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3734 - accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3713 - accuracy: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3691 - accuracy: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3670 - accuracy: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3648 - accuracy: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3627 - accuracy: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3606 - accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3584 - accuracy: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3563 - accuracy: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3542 - accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3520 - accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3499 - accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3478 - accuracy: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3457 - accuracy: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3436 - accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3414 - accuracy: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3393 - accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3372 - accuracy: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3351 - accuracy: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3330 - accuracy: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3309 - accuracy: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3288 - accuracy: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3267 - accuracy: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3246 - accuracy: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3225 - accuracy: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3204 - accuracy: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3183 - accuracy: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3162 - accuracy: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3141 - accuracy: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3121 - accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3100 - accuracy: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3079 - accuracy: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3058 - accuracy: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3038 - accuracy: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3017 - accuracy: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2996 - accuracy: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2976 - accuracy: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2955 - accuracy: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2934 - accuracy: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2914 - accuracy: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2893 - accuracy: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2873 - accuracy: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2852 - accuracy: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2832 - accuracy: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2811 - accuracy: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2791 - accuracy: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2770 - accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2750 - accuracy: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2729 - accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2709 - accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2689 - accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2669 - accuracy: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2648 - accuracy: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2628 - accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2608 - accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2588 - accuracy: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2567 - accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2547 - accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2527 - accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2507 - accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2487 - accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2467 - accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2447 - accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2427 - accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2407 - accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2387 - accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2367 - accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2347 - accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2327 - accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2307 - accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2268 - accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2248 - accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2228 - accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2209 - accuracy: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 832us/step - loss: 1.2189 - accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 973us/step - loss: 1.2169 - accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2150 - accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2130 - accuracy: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2110 - accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2091 - accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2071 - accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2052 - accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2032 - accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2013 - accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1993 - accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1974 - accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1955 - accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1935 - accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1916 - accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1897 - accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1877 - accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1858 - accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1839 - accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1820 - accuracy: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1800 - accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1781 - accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1762 - accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1743 - accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1724 - accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1705 - accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1686 - accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1667 - accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1648 - accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1629 - accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1610 - accuracy: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1591 - accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1572 - accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1554 - accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1535 - accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1516 - accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1497 - accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1478 - accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1460 - accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1441 - accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1422 - accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1404 - accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1385 - accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1367 - accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1348 - accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1330 - accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1311 - accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1293 - accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1274 - accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1256 - accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1237 - accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1219 - accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1201 - accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1182 - accuracy: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1164 - accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1146 - accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1128 - accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1109 - accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1091 - accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1073 - accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1055 - accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1037 - accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1019 - accuracy: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1001 - accuracy: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0983 - accuracy: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0965 - accuracy: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0947 - accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0929 - accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0911 - accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0893 - accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0875 - accuracy: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0858 - accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0840 - accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0804 - accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0787 - accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 862us/step - loss: 1.0769 - accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0751 - accuracy: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0734 - accuracy: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 979us/step - loss: 1.0716 - accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0698 - accuracy: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0681 - accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0663 - accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0646 - accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0594 - accuracy: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0576 - accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0559 - accuracy: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0542 - accuracy: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0524 - accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0507 - accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0490 - accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0455 - accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0438 - accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0404 - accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0387 - accuracy: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0370 - accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0353 - accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0336 - accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0319 - accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0302 - accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0285 - accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0268 - accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0251 - accuracy: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0218 - accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0201 - accuracy: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0184 - accuracy: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0168 - accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0151 - accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0134 - accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0101 - accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0084 - accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0068 - accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0051 - accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0035 - accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0018 - accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0002 - accuracy: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9986 - accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9969 - accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9953 - accuracy: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9936 - accuracy: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9920 - accuracy: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9904 - accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9888 - accuracy: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9871 - accuracy: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9855 - accuracy: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9823 - accuracy: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9807 - accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9775 - accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9759 - accuracy: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9727 - accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9711 - accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9695 - accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9663 - accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9647 - accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9632 - accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9616 - accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9600 - accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9584 - accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9569 - accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9553 - accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9537 - accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9522 - accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9506 - accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9491 - accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9475 - accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9460 - accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9444 - accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9429 - accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9413 - accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9398 - accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9383 - accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9367 - accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9352 - accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9337 - accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9322 - accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9306 - accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9291 - accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9276 - accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9261 - accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9246 - accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9231 - accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9216 - accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9201 - accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9171 - accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9126 - accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9111 - accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9067 - accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9052 - accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9023 - accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9008 - accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8993 - accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8979 - accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8964 - accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8949 - accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 839us/step - loss: 0.8935 - accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8920 - accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8906 - accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8892 - accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8877 - accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8863 - accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8848 - accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8834 - accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8820 - accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8805 - accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8791 - accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8763 - accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8735 - accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8720 - accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8706 - accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8692 - accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8678 - accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8664 - accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8650 - accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8622 - accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8595 - accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8581 - accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8567 - accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8553 - accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8539 - accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8512 - accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8498 - accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8485 - accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8471 - accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8444 - accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8430 - accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8417 - accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8403 - accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8390 - accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8376 - accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8363 - accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8350 - accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8336 - accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8323 - accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8310 - accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8283 - accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8270 - accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8257 - accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8243 - accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8230 - accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8217 - accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8204 - accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8191 - accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8178 - accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8165 - accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8113 - accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8087 - accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8074 - accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8062 - accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8049 - accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8036 - accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8023 - accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7998 - accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7985 - accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7960 - accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7948 - accuracy: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7935 - accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7922 - accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7910 - accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7885 - accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7860 - accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7823 - accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7799 - accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7786 - accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7762 - accuracy: 0.0476\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.0476\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.0476\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7726 - accuracy: 0.0476\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7713 - accuracy: 0.0476\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.0476\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7689 - accuracy: 0.0476\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7677 - accuracy: 0.0476\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7665 - accuracy: 0.0476\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.0476\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7641 - accuracy: 0.0476\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.0476\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7618 - accuracy: 0.0476\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7606 - accuracy: 0.0952\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7594 - accuracy: 0.0952\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.0952\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7570 - accuracy: 0.0952\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.0952\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7547 - accuracy: 0.0952\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7535 - accuracy: 0.0952\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.1429\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7512 - accuracy: 0.1429\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7500 - accuracy: 0.1429\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7488 - accuracy: 0.1429\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7477 - accuracy: 0.1429\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7465 - accuracy: 0.1905\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7454 - accuracy: 0.1905\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7442 - accuracy: 0.1905\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7431 - accuracy: 0.1905\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.2381\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7408 - accuracy: 0.2381\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.2381\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7385 - accuracy: 0.2381\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7374 - accuracy: 0.2381\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.2381\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.2381\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.2381\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.2381\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7317 - accuracy: 0.2381\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.2381\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.2381\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.2857\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.2857\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.2857\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7250 - accuracy: 0.2857\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7239 - accuracy: 0.3333\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.3810\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.3810\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.3810\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.3810\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.3810\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.3810\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.3810\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.4286\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7140 - accuracy: 0.4286\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.4286\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.4286\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.4286\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.4286\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.4286\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.4286\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.4286\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7054 - accuracy: 0.4286\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.4286\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.4286\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.4286\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.4286\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.4286\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.4286\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.4286\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.4286\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.4762\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5238\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5238\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5238\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5238\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5714\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5714\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5714\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5714\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.6190\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.6667\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6667\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6667\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.6667\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.6667\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.6667\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.6667\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.6667\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.6667\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.6667\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.6667\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.6667\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6667\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7143\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.7143\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.7619\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7619\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.7619\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.7619\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.7619\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.7619\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.7619\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7619\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.7619\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.7619\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.7619\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.7619\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7619\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.7619\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.7619\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.7619\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.7619\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7619\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.7619\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7619\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.7619\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.7619\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.7619\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.7619\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.7619\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.7619\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7619\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7619\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.7619\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7619\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7619\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.7619\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.7619\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.7619\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.7619\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7619\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7619\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7619\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.7619\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7619\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7619\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.7619\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.7619\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7619\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7619\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.7619\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.7619\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7619\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7619\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7619\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7619\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7619\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7619\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7619\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7619\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7619\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.8095\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.8095\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.8095\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.8095\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.8095\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.8095\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.8095\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.8095\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.8095\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.8571\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.8571\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.8571\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.8571\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.8571\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.8571\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.8571\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.8571\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.8571\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.8571\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.8571\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.8571\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.8571\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.8571\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.8571\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.8571\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.8571\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.8571\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.8571\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.8571\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.8571\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8571\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.8571\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.8571\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.8571\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.8571\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.8571\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.8571\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.8571\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.8571\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.8571\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8571\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.8571\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.8571\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.9048\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.9048\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.9048\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.9048\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.9048\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.9048\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5773 - accuracy: 0.9048\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.9048\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.9048\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.9048\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.9048\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.9048\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.9048\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.9048\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.9048\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.9048\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.9048\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.9048\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5680 - accuracy: 0.9048\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.9048\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.9048\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.9048\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5649 - accuracy: 0.9048\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.9048\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.9048\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.9048\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.9048\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.9048\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.9048\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.9048\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.9048\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.9048\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.9048\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.9048\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.9048\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.9048\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5544 - accuracy: 0.9048\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.9048\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.9048\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.9048\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.9048\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.9048\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.9048\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.9048\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.9048\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.9048\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.9048\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.9048\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.9048\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.9048\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.9048\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.9048\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.9048\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.9048\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5414 - accuracy: 0.9048\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.9048\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.9048\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.9048\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.9048\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.9048\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.9048\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.9048\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.9048\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.9048\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.9048\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.9048\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.9048\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.9048\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.9048\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.9048\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.9048\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.9048\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.9048\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.9048\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.9048\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.9048\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.9048\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.9048\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.9048\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.9048\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.9048\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.9048\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.9048\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.9048\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.9048\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.9048\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.9048\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.9048\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.9048\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.9048\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.9048\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.9048\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.9048\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.9048\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.9048\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.9048\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.9048\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.9048\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.9048\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.9048\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.9048\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.9048\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.9048\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.9048\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.9048\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.9048\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.9048\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.9048\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.9048\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.9048\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.9048\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.9048\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.9048\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.9048\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.9048\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.9048\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.9048\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.9048\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.9048\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.9048\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.9048\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.9048\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.9048\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.9048\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.9048\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.9048\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.9048\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.9048\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.9048\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.9048\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.9048\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.9048\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.9048\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.9048\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.9048\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.9048\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.9048\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.9048\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.9048\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.9048\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.9048\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.9048\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.9048\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.9048\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.9048\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.9048\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.9048\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.9048\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.9048\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.9048\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.9048\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.9048\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.9048\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.9048\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.9048\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.9048\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.9048\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4757 - accuracy: 0.9048\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.9048\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.9048\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.9048\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.9048\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.9048\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.9048\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.9048\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.9048\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.9048\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.9048\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.9048\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.9048\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.9048\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.9048\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.9048\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.9048\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.9048\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.9048\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9048\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.9048\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9048\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.9048\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.9048\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.9048\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.9048\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.9048\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.9048\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.9048\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.9048\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.9048\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.9048\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.9048\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.9048\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.9048\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.9048\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.9048\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.9048\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.9048\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.9048\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.9048\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.9048\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.9048\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.9048\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.9048\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.9048\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.9048\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.9048\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.9048\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.9048\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.9048\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.9048\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.9048\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.9048\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.9048\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.9048\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.9048\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.9048\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.9048\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.9048\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.9048\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.9048\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.9048\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.9048\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.9048\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.9048\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.9048\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.9048\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.9048\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.9048\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.9048\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.9048\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.9048\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.9048\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.9048\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.9048\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.9048\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.9048\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.9048\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.9048\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.9048\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.9048\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.9048\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.9048\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.9048\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.9048\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.9048\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.9048\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.9048\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.9048\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.9048\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.9048\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.9048\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.9048\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.9048\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.9048\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.9048\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.9048\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.9048\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.9048\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.9048\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.9048\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.9048\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.9048\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.9048\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.9048\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.9048\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.9048\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.9048\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.9048\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.9048\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.9048\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.9048\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.9048\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.9048\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.9048\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.9048\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.9048\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.9048\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.9048\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.9048\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.9048\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.9048\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.9048\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.9048\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.9048\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.9048\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.9048\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.9048\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.9048\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.9048\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.9048\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.9048\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.9048\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.9048\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.9048\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.9048\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.9048\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.9048\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.9048\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.9048\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.9048\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.9048\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.9048\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.9048\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.9048\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.9048\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.9048\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.9048\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.9048\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.9048\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.9048\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.9048\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.9048\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.9048\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.9048\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.9048\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.9048\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.9048\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.9048\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.9048\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.9048\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.9048\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.9048\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.9048\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3953 - accuracy: 0.9048\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.9048\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.9048\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.9048\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.9048\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.9048\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.9048\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.9048\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.9048\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.9048\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.9048\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.9048\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.9048\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.9048\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.9048\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.9048\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.9048\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.9048\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.9048\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.9048\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.9048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a51f9b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB40x9e5FiSX",
        "outputId": "1f8c700d-9de1-41b8-b6c8-32aa3c3c99d5"
      },
      "source": [
        "model.evaluate(x_input, y_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.9048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38672393560409546, 0.9047619104385376]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uJ2auqIFa7x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWdpRaQ2Pp8G"
      },
      "source": [
        "**KERAS IMPLEMENTATION OF MNIST DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKj50k79Px_D"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#keras liberies\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j7V70USQPOK"
      },
      "source": [
        "**Load the MNIST data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOGCL0xIQKig",
        "outputId": "5223c7c4-bd1c-487f-cd20-30a600a16e03"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_features, train_labels),(test_features, test_labels) = mnist.load_data()\n",
        "train_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyrL9-SJQj9P"
      },
      "source": [
        "train_features, test_features = train_features / 255.0, test_features / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMUDKg6QyM-"
      },
      "source": [
        "#build the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dense(units=20, activation = 'relu'))\n",
        "model.add(Dropout(.20))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7qekHSaRV0g"
      },
      "source": [
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_0TY45DRV7N",
        "outputId": "9b041114-f1c7-4955-9c46-8b16c43dc6a1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 20)                1020      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 40,480\n",
            "Trainable params: 40,480\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crEfXKC6RWQm",
        "outputId": "6b69d314-1662-4f6c-cd7c-f8adc8ea2b26"
      },
      "source": [
        "model.fit(train_features, train_labels, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 1.3038 - accuracy: 0.5597\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7559 - accuracy: 0.7515\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.6465 - accuracy: 0.7958\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5820 - accuracy: 0.8235\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5347 - accuracy: 0.8413\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4922 - accuracy: 0.8562\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4565 - accuracy: 0.8671\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4292 - accuracy: 0.8749\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4053 - accuracy: 0.8801\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3868 - accuracy: 0.8867\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3668 - accuracy: 0.8923\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3522 - accuracy: 0.8970\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8992\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3267 - accuracy: 0.9037\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3120 - accuracy: 0.9080\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3002 - accuracy: 0.9120\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2897 - accuracy: 0.9157\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2802 - accuracy: 0.9179\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2696 - accuracy: 0.9219\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2650 - accuracy: 0.9226\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2554 - accuracy: 0.9254\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2494 - accuracy: 0.9265\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2435 - accuracy: 0.9283\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2395 - accuracy: 0.9293\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2334 - accuracy: 0.9319\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2284 - accuracy: 0.9334\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2233 - accuracy: 0.9352\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2172 - accuracy: 0.9355\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2128 - accuracy: 0.9362\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2087 - accuracy: 0.9384\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2057 - accuracy: 0.9398\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2023 - accuracy: 0.9409\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1970 - accuracy: 0.9419\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1937 - accuracy: 0.9432\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1910 - accuracy: 0.9443\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1918 - accuracy: 0.9421\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1875 - accuracy: 0.9444\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1855 - accuracy: 0.9457\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1830 - accuracy: 0.9468\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1790 - accuracy: 0.9468\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1791 - accuracy: 0.9473\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1757 - accuracy: 0.9474\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1740 - accuracy: 0.9481\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1727 - accuracy: 0.9481\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1685 - accuracy: 0.9493\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1687 - accuracy: 0.9502\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1642 - accuracy: 0.9513\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1629 - accuracy: 0.9509\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1611 - accuracy: 0.9521\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1605 - accuracy: 0.9509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a4d942f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg_2Xi_9SCmA",
        "outputId": "d98affdd-c9cd-47af-c6d3-48d089c53dfc"
      },
      "source": [
        "model.evaluate(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 800us/step - loss: 0.1393 - accuracy: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13933902978897095, 0.9599999785423279]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z5WAAJdRWWG",
        "outputId": "f397788d-71ab-4f40-e335-564c9d302606"
      },
      "source": [
        "#load random images fromthe dataset and test the model\n",
        "loc = 10\n",
        "test_image = test_features[loc]\n",
        "test_image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E18AUo52Sd-B"
      },
      "source": [
        "test_image = test_image.reshape(1,28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riw9H8H8SJlT",
        "outputId": "22a0efc3-6a9c-477b-9518-2e2caf1ed3f2"
      },
      "source": [
        "test_image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPuEIrzSJ0p",
        "outputId": "077c4ded-ccd6-45dd-e3bd-b6bd1fbd1038"
      },
      "source": [
        "result = model.predict(test_image)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9913776e-01 1.7210574e-13 2.9351786e-04 5.7910221e-08 1.4821022e-10\n",
            "  5.1248452e-04 5.5324050e-05 8.1301778e-07 4.1863676e-10 1.0084115e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-t7CLxISJ7K",
        "outputId": "ed3a8a29-ae90-4543-a19c-1a5f836e7821"
      },
      "source": [
        "result.argmax()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JaLzAK_SKBE",
        "outputId": "b8842c0c-b4c8-409e-ebb2-a3d15d9dafb1"
      },
      "source": [
        "test_labels[loc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "sdJJ--tIRWbf",
        "outputId": "8fc352db-ee3a-4788-9e37-b09b46c0544f"
      },
      "source": [
        "plt.imshow(test_features[loc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6a4bfb4390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZeoo4qnpEkC"
      },
      "source": [
        "**Keras Implementation of Sonar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4dPcR9WpNpZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Import Keras libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "CXxWFNXHpRgq",
        "outputId": "4e657548-2a2d-4416-9e8b-c6529fae1244"
      },
      "source": [
        "df = pd.read_csv('sonar.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  ...  attribute_59  attribute_60  Class\n",
              "0       0.0200       0.0371       0.0428  ...        0.0090        0.0032   Rock\n",
              "1       0.0453       0.0523       0.0843  ...        0.0052        0.0044   Rock\n",
              "2       0.0262       0.0582       0.1099  ...        0.0095        0.0078   Rock\n",
              "3       0.0100       0.0171       0.0623  ...        0.0040        0.0117   Rock\n",
              "4       0.0762       0.0666       0.0481  ...        0.0107        0.0094   Rock\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKsd0HyZpUxn"
      },
      "source": [
        "X_input = df.iloc[:, :-1]\n",
        "Y_label = df['Class'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShEcY1QhpgVf"
      },
      "source": [
        "labelencoder_Y = LabelEncoder() \n",
        "Y_label = labelencoder_Y.fit_transform(Y_label)\n",
        "Y_label = Y_label.reshape([208, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui5qKdGlpkc8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(300,input_dim=60, activation = 'relu'))\n",
        "model.add(Dense(200, activation = 'relu'))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFjXuXbKpn_x"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl27PR4kpqie",
        "outputId": "ac498595-daf4-4d99-ba3a-d47b7d42bcb6"
      },
      "source": [
        "model.fit(X_input, Y_label, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5192\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6490\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7837\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8029\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8173\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7596\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8125\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8606\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8750\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8750\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8846\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9038\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.8942\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9279\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9279\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9375\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9615\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9567\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9471\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9663\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9712\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9375\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9519\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9375\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9471\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9567\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9952\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9904\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a4bf9f2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ompdRYbZpvZ8",
        "outputId": "15d66cba-3a51-4de9-f42f-8ee053a209e4"
      },
      "source": [
        "model.evaluate(X_input, Y_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.025134406983852386, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uay8Y0uz6ZRZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaOKXawJ6b3x",
        "outputId": "bf796a3e-5d96-4a09-b31f-69b8708feb03"
      },
      "source": [
        "A = tf.Variable([[1,2,3],[4,5,6],[7,8,9]])\n",
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6],\n",
              "       [7, 8, 9]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL9i6Njt6m8u",
        "outputId": "2f178739-f9d2-48b6-dc1f-a93c98d41e59"
      },
      "source": [
        "B = tf.Variable([[1,0,-1],[1,0,-1],[1,0,-1]])\n",
        "B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
              "array([[ 1,  0, -1],\n",
              "       [ 1,  0, -1],\n",
              "       [ 1,  0, -1]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz4b6vnw7Aps",
        "outputId": "752a98af-8167-4db8-b851-c29999c0476f"
      },
      "source": [
        "mult_out = tf.math.multiply(A,B)\n",
        "mult_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 1,  0, -3],\n",
              "       [ 4,  0, -6],\n",
              "       [ 7,  0, -9]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GMBxZYW7MlJ",
        "outputId": "d9be992c-0eb2-45b2-aa3c-bdc65b978c29"
      },
      "source": [
        "conv_out = tf.math.reduce_sum(mult_out)\n",
        "conv_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=-6>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ1IG7dpAQWw"
      },
      "source": [
        "**CNN Keras implementation on the MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7VbdpxRAPcA"
      },
      "source": [
        "import tensorflow.keras.datasets.mnist as mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6jqN3jEAe7x"
      },
      "source": [
        "(features_train, label_train), (features_test, label_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j744oLGAjSO",
        "outputId": "1092de4a-d564-4362-e622-af7db07f6020"
      },
      "source": [
        "label_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Fbza4IAo9K",
        "outputId": "a3f23f96-c81d-47c1-f1c9-c148ce3c75ca"
      },
      "source": [
        "features_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ9cIUi8A0ED"
      },
      "source": [
        "#Reshape the training and testing sets with the dimensions (number_observations, 28, 28, 1):\n",
        "features_train = features_train.reshape(60000, 28, 28, 1)\n",
        "features_test = features_test.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7BRfp2rA-2t"
      },
      "source": [
        "#Standardize features_train and features_test by dividing them by 255:\n",
        "features_train = features_train / 255.0\n",
        "features_test = features_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPP2AY5BD4J"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkbrLvn8BHyj"
      },
      "source": [
        "#Set 8 as the seed for numpy and tensorflow using np.random_seed() and tf.random.set_seed(), respectively:\n",
        "np.random.seed(8)\n",
        "tf.random.set_seed(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMtaRItvBlJ6"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "conv_layer1 = layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1))\n",
        "conv_layer2 = layers.Conv2D(64, (3,3), activation='relu')\n",
        "fc_layer1 = layers.Dense(128, activation='relu')\n",
        "fc_layer2 = layers.Dense(10, activation='softmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLLddakrBzAi",
        "outputId": "b85a6438-21cc-48c0-b3a7-48af56f5a549"
      },
      "source": [
        "model.add(conv_layer1)\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(conv_layer2)\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(fc_layer1)\n",
        "model.add(fc_layer2)\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WMYHMUMCAZT",
        "outputId": "9faacdc2-9a4e-4cf6-ed16-fd7712033d3d"
      },
      "source": [
        "model.fit(features_train, label_train, epochs=5, validation_split = 0.2, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 - 55s - loss: 0.1368 - accuracy: 0.9574 - val_loss: 0.0572 - val_accuracy: 0.9830\n",
            "Epoch 2/5\n",
            "1500/1500 - 55s - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.0390 - val_accuracy: 0.9878\n",
            "Epoch 3/5\n",
            "1500/1500 - 55s - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0378 - val_accuracy: 0.9886\n",
            "Epoch 4/5\n",
            "1500/1500 - 55s - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0376 - val_accuracy: 0.9900\n",
            "Epoch 5/5\n",
            "1500/1500 - 55s - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0434 - val_accuracy: 0.9890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a515c7710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhVbzOlFCHTF",
        "outputId": "99100882-caa4-4351-9b38-3cbe4c271884"
      },
      "source": [
        "model.evaluate(features_test, label_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0336 - accuracy: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03362766280770302, 0.989799976348877]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6YNE9V0Kg00"
      },
      "source": [
        "**Image Classification (CIFAR-10) with Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FAiLGoEKlEH"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2t5o1wBKsAi",
        "outputId": "4fbdd584-f8df-41f9-e65d-ef58d4e94266"
      },
      "source": [
        "(features_train, label_train), (features_test, label_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIVjihXLKt0C",
        "outputId": "b8261756-a27e-42a9-ed66-7e779c43d41e"
      },
      "source": [
        "features_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RtYNLeEKwJa"
      },
      "source": [
        "batch_size = 16\n",
        "img_height = 32\n",
        "img_width = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWOjxPUrK1pu"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "504T17aZK2yn"
      },
      "source": [
        "train_img_gen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1,\n",
        " height_shift_range=0.1, horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coJF2loyK7Cn"
      },
      "source": [
        "val_img_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5LdvjNjK9h_"
      },
      "source": [
        "train_data_gen = train_img_gen.flow(features_train, label_train,\n",
        " batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaj0fc7qLCsR"
      },
      "source": [
        "val_data_gen = train_img_gen.flow(features_test, label_test,\n",
        " batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67i1-dSsLFEJ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2_rLendLHWb"
      },
      "source": [
        "np.random.seed(8)\n",
        "tf.random.set_seed(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCFSMiTLLU8"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(64, 3, activation='relu', input_shape=(img_height,\n",
        " img_width ,3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk1As9JWLNyU"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqS3RfoRLQIe"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vImAJK_zLR8g",
        "outputId": "61817654-697a-47a8-b064-cdb9b3db26f3"
      },
      "source": [
        "model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=len(features_train) // batch_size, epochs=5,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=len(features_test) // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-160-a0d5eb69b5e8>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/5\n",
            "3125/3125 [==============================] - 161s 51ms/step - loss: 1.5091 - accuracy: 0.1027 - val_loss: 1.2692 - val_accuracy: 0.0672\n",
            "Epoch 2/5\n",
            "3125/3125 [==============================] - 158s 51ms/step - loss: 1.1843 - accuracy: 0.0966 - val_loss: 1.1058 - val_accuracy: 0.0728\n",
            "Epoch 3/5\n",
            "3125/3125 [==============================] - 157s 50ms/step - loss: 1.0843 - accuracy: 0.0976 - val_loss: 1.0567 - val_accuracy: 0.1057\n",
            "Epoch 4/5\n",
            "3125/3125 [==============================] - 156s 50ms/step - loss: 1.0180 - accuracy: 0.0981 - val_loss: 0.9996 - val_accuracy: 0.1146\n",
            "Epoch 5/5\n",
            "3125/3125 [==============================] - 156s 50ms/step - loss: 0.9722 - accuracy: 0.0995 - val_loss: 0.9658 - val_accuracy: 0.1210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a4fdf0fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    }
  ]
}